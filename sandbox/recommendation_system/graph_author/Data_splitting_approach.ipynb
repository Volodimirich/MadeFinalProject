{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21GoleC87c3B"
   },
   "source": [
    "#Описание подхода для разделения данных (спринт 3) (Команда № 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvlWmf4Y7nwX"
   },
   "source": [
    "##I. Подготовка данных\n",
    "\n",
    "### 1. Отбор авторов и статей (стратегия):\n",
    "\n",
    "  1) В первую очередь мы отобрали статьи, на которых обучали модели кластеризации и классификации, а именно:\n",
    "- по году публикации >= 1990\n",
    "- по числу цитирований > 2\n",
    "\n",
    "Для рекомендаций соавторов было решено использовать связи авторов по статьям, поэтому из данных удаляем все статьи с одним автором:\n",
    "- по числу авторов > 1 (чтобы был соавтор)\n",
    "\n",
    "### 2. Строим таблицу взаимодействия авторов по статьям (матрица А).\n",
    "\n",
    "     Автор        Соавтор      Кол-во совместных публикаций\n",
    "    auth_id_1   co_auth_id_1     article_number\n",
    "    auth_id_1   co_auth_id_2     article_number\n",
    "     ...           ...           ... \n",
    "\n",
    "    auth_id_N   co_auth_id_M     article_number\n",
    "\n",
    "Здесь последний столбец - количество совместных публикаций конкретных автора и соавтора. Причем для каждой статьи будет по крайней мере 2 строки, отличающихся только следованием author_id и co_author_id. Если в статье количество авторов больше 2, то для каждой упорядоченной пары соавторов будет своя строка.\n",
    "\n",
    "  2) В таблице А группируем значения по столбцу Автор и удаляем тех авторов, у которых количество соавторов меньше 3 (это число далее будет уточняться в процессе разработки модели рекомендаций, на основе тестовых характеристик). Это сделано для того, чтобы при разделении данных на трэйн и тест у нас не оказалось авторов с единственным взаимодействием, так как этого не достаточно для выроботки рекомендаций по соавторам.\n",
    "\n",
    "### 3. Из таблицы **А** строим матрицу инцидентности **C** для графа взаимодействия авторов.\n",
    "Отличием этой матрицы от \"классической\" матрицы инцидентности является только то, что на пересечении двух авторов будет стоять вес ребра:  0 (если у них нет совместных статей) или article_number (количество совместных статей). \n",
    "\n",
    "Матрица инцидентности **C** может быть построена с помощью pandas.pivot_table. В результате будем иметь разреженную матрицу размера $N \\times N$, в которой большинство значений $val\\_ij=0$:\n",
    "\n",
    "$\\begin{array}{|c|c|} \\hline\n",
    "authors\\_id & author\\_id\\_1 & author\\_id\\_2 & \\dots & author\\_id\\_N\\\\ \\hline\n",
    "author\\_id\\_1 & val\\_11 & val\\_12 & \\dots & val\\_1N\\\\\n",
    "author\\_id\\_2 & val\\_21 & val\\_22 & \\dots & val\\_2N\\\\\n",
    "author\\_id\\_3 & val\\_31 & val\\_32 & \\dots & val\\_3N\\\\\n",
    "\\dots & \\dots & \\dots & \\dots & \\dots\\\\\n",
    "author\\_id\\_N & val\\_N1 & 0 & \\dots & val\\_NN\\\\ \\hline\n",
    "\\end{array}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0t9dtz7EBFX"
   },
   "source": [
    "#II. Сплиттинг данных\n",
    "\n",
    " Были рассмотрены следующие стратегии разделения данных:\n",
    "\n",
    "\ta) случайное разделение: из каждой строки для тестовой выборки выбираем 20% ненулевых значений;\n",
    "\tб) Leave-One-Last-Item: из каждой строки для тестовой выборки выбираем элемент с максимальным годом публикации (год можно дополнительно учитывать в А)\n",
    "\tв) temporal split: из каждой строки для тестовой выборки выбираем элементы, которые соответствуют публикациям после заданной даты (например после 2020)\n",
    "\tг) user-split: 20% случайных авторов отнести к тестовой выборке. \n",
    "\n",
    "  1) Так как \"хорошая\" рекомендация соавтора - это соавтор занимающийся исследованием схожей научной проблематики, и как правило ученые не меняют направление научной деятельности со временем, то мы отбросили методы с временными привязками Leave-One-Last-Item и temporal split. Кроме того, даже если наше предположение не верно, мы всегда можем сгруппировать наших авторов по тематикам с помощью обученой модели классификации и давать рекомендации в рамках одного класса. \n",
    "  \n",
    "  2) Для тестовой выборки было решено использовать случайное разделение данных, а именно брать 20% случайных непустых значений из каждой строки в матрице **С**. Кроме того в тестовый набор попадут те авторы, которые были отброшены в п.2.2 (I), т.е. у них было мало взаимодействий (фактически это метод г)). Такие тестовые записи будут использоваться для анализа рекомендации для \"холодного старта\", например, если мы знаем только, что автор относится к какому-то классу, и мы должны рекомендовать ему каких-то соавторов из этого класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXC9BSd5SJxq"
   },
   "source": [
    "#III. Метрики для оценки качества рекомендаций\n",
    "\n",
    "Были рассмотрены следующие группы метрик для измерения качества рекомендаций:\n",
    "\n",
    "1. Метрики сходства на основе векторов признаков авторов\n",
    "  а) Косинусное сходство ( Cosine similarity)\n",
    "Чтобы вычислить сходство между двумя авторами, мы просто берем косинус между двумя векторами авторов. Косинусное сходство лучше всего подходит, если имеется много многомерных признаков (https://i0.wp.com/neptune.ai/wp-content/uploads/Recommender-Systems-ML-Metrics-vs-Business-Metrics_10.png?resize=474%2C110&ssl=1)\n",
    "\n",
    "  б) Сходство Жаккара (Jaccard similarity)\n",
    "Сходство Жаккара - это размер пересечения, деленный на размер объединения двух наборов элементов https://i0.wp.com/neptune.ai/wp-content/uploads/Recommender-Systems-ML-Metrics-vs-Business-Metrics_18.png?resize=437%2C252&ssl=1\n",
    "\n",
    "  в) Расстояние Эвклида (Euclidean distance)\n",
    "Расстояние между двумя авторами, равно длине соединяющих их отрезков. Пространство предпочтений — это доступные элементы (соавторы), а оси — это авторы, с которыми уже было взаимодействие. На основе имеющихся взаимодействий мы ищем соавторов со схожими научными интересами. Чем меньше расстояние между двумя авторами, тем выше вероятность того, что они интересуются той же научной проблемой https://i0.wp.com/neptune.ai/wp-content/uploads/Recommender-Systems-ML-Metrics-vs-Business-Metrics_5.png?resize=554%2C86&ssl=1\n",
    "\n",
    "  г) Коэффициент корреляции Пирсона(Pearson correlation coefficient (PCC))\n",
    "PCC — это мера наклона линии, которая представляет отношение между двумя векторами авторов. Она может варьироваться от -1 до 1, 0 означает отсутствие линейной корреляции https://i0.wp.com/neptune.ai/wp-content/uploads/Recommender-Systems-ML-Metrics-vs-Business-Metrics_19.png?resize=535%2C141&ssl=1\n",
    "\n",
    "  \n",
    "  2. Предсказательные метрики\n",
    "\n",
    "Предсказательные метрики касаются того, насколько рейтинги рекомендательных систем близки к рейтингам пользователей. Они являются хорошим выбором для небинарных задач. \n",
    "\n",
    "  а) MAE — это средняя величина различий между рекомендацией и соответствующей оценкой, которую очень легко интерпретировать. Обратите внимание, что он не наказывает за большие ошибки или выбросы и присваивает таким случаям равные веса с другими. Это означает, что MAE дает довольно целостное представление о точности рейтинга, а не штрафует за большие ошибки https://i0.wp.com/neptune.ai/wp-content/uploads/Recommender-Systems-ML-Metrics-vs-Business-Metrics_14.png?resize=378%2C119&ssl=1\n",
    "\n",
    "  б) RMSE — это квадратичная метрика, которая также измеряет среднюю величину, но квадратный корень имеет значение. RMSE придает большой вес большим ошибкам. Это означает, что это более полезно, когда выбросы нежелательны https://i0.wp.com/neptune.ai/wp-content/uploads/Recommender-Systems-ML-Metrics-vs-Business-Metrics_20-1.png?resize=471%2C141&ssl=1\n",
    "\n",
    "На практике как RMSE, так и MAE обычно проверяются для моделей совместных рекомендаций на наборе данных с перекрестной проверкой в ​​K-кратном порядке. Однако с точки зрения бизнеса важны не только самые высокие значения RMSE или MAE, но и показатели неточности, используемые для оценки.\n",
    "\n",
    "  3. Классификационные метрики.\n",
    "  \n",
    "  Показатели классификации оценивают способность рекомендательных систем принимать решения. Они являются хорошим выбором для таких задач, как определение релевантных или нерелевантных продуктов для пользователя. Для метрик поддержки принятия решений точный рейтинг игнорируется, тогда как для методов, основанных на ранжировании, он имеет неявное влияние посредством ранжирования. \n",
    "\n",
    "  а) Precision@k\n",
    "\n",
    "  Precision@k - доля топ k рекомендаций, которые релевантны пользователю\n",
    "\n",
    "  $P = \\frac{\\text{# of  top  k  recommendations  that  are  relevant}}{\\text{# of items that are recommended}}$\n",
    "\n",
    "  б) Mar@K and Map@K\n",
    "\n",
    "  Среднее значение отзыва при K (Mar@k) измеряет recall при k-й рекомендации. Mar@k учитывает порядок рекомендаций и наказывает правильные рекомендации в зависимости от порядка рекомендаций. Map@k и Mar@k идеально подходят для оценки упорядоченного списка рекомендаций. \n",
    "\n",
    "  в) Recall@k или HitRatio@k\n",
    "\n",
    "  Recall@k или HitRatio@k — это часть k лучших рекомендуемых элементов, которые находятся в наборе элементов, релевантных пользователю. Чем больше k, тем выше коэффициент попаданий, поскольку выше вероятность того, что правильный ответ будет включен в рекомендации.\n",
    "  \n",
    "  $R = \\frac{\\text{(# of top k recommendations that are relevant}}{\\text{# of all relevant items}}$\n",
    "\n",
    "  г) Средняя точность (AP)\n",
    "  В то время как precision@k (P(k)) учитывает только подмножество ваших рекомендаций от ранга 1 до k, средняя точность вознаграждает нас за размещение правильных рекомендаций в начале списка. Например, если precision@5 это константа, то AP@5 убывает с рангом рекомндованного объекта. Очень важно отметить, что AP не будет наказывать нас за включение дополнительных рекомендаций в наш список. При его использовании мы должны убедиться, что рекомендуем только лучшие объекты  https://i0.wp.com/neptune.ai/wp-content/uploads/Recommender-Systems-ML-Metrics-vs-Business-Metrics_27.png?resize=480%2C86&ssl=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BR_06H7j7cO_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
